{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import yaml\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config_train.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "data_files = config['data_files']\n",
    "dataset = load_dataset('json', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config['model']\n",
    "trained_checkpoint = config['trained_checkpoint']\n",
    "\n",
    "if model == \"bart\":\n",
    "    from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "    model_checkpoint = \"facebook/bart-large\"\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_checkpoint)\n",
    "    model = BartForConditionalGeneration.from_pretrained(trained_checkpoint)\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Example 0 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Uriah Hawthorne works for QuantumLeap Innovations and is coworkers with  Daphne Barrington. Their stock is definitely going to go up!\n",
      "HyperNexus Innovations. They have a big project coming up.\n",
      "#### Example 1 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Anneliese Worley works for AeroZenith Technologies and is coworkers with  Owen Larkspur. Their stock is definitely going to go up!\n",
      "HyperNexus Innovations. They have a big project coming up.\n",
      "#### Example 2 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Tyler Oakridge works for StellarWave Solutions and is coworkers with  Dominic Mullins. Their stock is definitely going to go up!\n",
      "AstroFusion Solutions. They have a big project coming up.\n",
      "#### Example 3 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Sierra Pemberton works for TerraVista Corp and is coworkers with  Juliette Radcliffe. Their stock is definitely going to go up!\n",
      "HyperNexus Innovations. They have a big project coming up.\n",
      "#### Example 4 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Theodore Sterling works for NexaFusion Enterprises and is coworkers with  Keith Silverton. Their stock is definitely going to go up!\n",
      "HyperEdge Technologies. They are part of the team that onboards new employees.\n",
      "#### Example 5 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Aurora Chamberlain works for ApexCrest Industries and is coworkers with  Garrett Bridgewell. Their stock is definitely going to go up!\n",
      "HyperNexus Innovations. They have a big project coming up.\n",
      "#### Example 6 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Leona Hargrove works for VortexPrime Systems and is coworkers with  Derek Lindenwood. Their stock is definitely going to go up!\n",
      "HyperNexus Innovations. They have a big project coming up.\n",
      "#### Example 7 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Graham Redwood works for ZenithSphere Networks and is coworkers with  Ryan Dunsworth. Their stock is definitely going to go up!\n",
      "HyperEdge Technologies. They have a big project coming up.\n",
      "#### Example 8 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Felix Dunford works for AuroraNova Labs and is coworkers with  Nolan Evergreen. Their stock is definitely going to go up!\n",
      "NexaFusion Enterprises. They have a big project coming up.\n",
      "#### Example 9 ####\n",
      "Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\n",
      "Zachary Norwood works for HelixPulse Dynamics and is coworkers with  Sabrina Fairchild. Their stock is definitely going to go up!\n",
      "HyperEdge Technologies. They have a big project coming up.\n"
     ]
    }
   ],
   "source": [
    "few_shot_examples = \"Example: Steven Blackburn works for Dobis PR and is coworkers with Horatio Bigall. Their stock is definitely going to go up!\"\n",
    "\n",
    "mask_self = True\n",
    "for i in range(10):\n",
    "    dataset_prompt = dataset['test']['prompt'][i]\n",
    "    prompt = few_shot_examples + '\\n' + dataset_prompt\n",
    "    completion = dataset['test']['completion'][i]\n",
    "    # TODO: Add details to dataset JSON to make masking easier\n",
    "    mask_name = ' '.join(dataset_prompt.split()[4:6])\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "    if mask_self:\n",
    "        unwanted_token_ids = tokenizer.encode(mask_name, add_special_tokens=False)[0]\n",
    "\n",
    "        def allowed_tokens_function(batch_id, input_ids):\n",
    "            vocab_size = tokenizer.vocab_size\n",
    "            # Allow all tokens except the unwanted one\n",
    "            return [i for i in range(vocab_size) if i != unwanted_token_ids]\n",
    "    else:\n",
    "        allowed_tokens_function = None\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=50,\n",
    "        # num_beams=5,\n",
    "        early_stopping=True,\n",
    "        prefix_allowed_tokens_fn=allowed_tokens_function\n",
    "    )\n",
    "\n",
    "    # Decode generated sequence\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    print(f\"#### Example {i} ####\")\n",
    "    print(prompt, completion)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is definitely'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(completion.split()[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reversal-curse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
