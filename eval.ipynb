{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import yaml\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config_train.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "data_files = config['data_files']\n",
    "dataset = load_dataset('json', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma',\n",
       " '/net/projects/clab/tnief/bidirectional-reversal/results/google/gemma-1.1-2b-it20240918_1438/checkpoint-50')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = config['model']\n",
    "trained_checkpoint = config['eval']['trained_checkpoint']\n",
    "model_name, trained_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb5fc6a0fd3472ba8dc75de1ddda86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model_name == \"bart\":\n",
    "    from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "    model_checkpoint = \"facebook/bart-large\"\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_checkpoint)\n",
    "    model = BartForConditionalGeneration.from_pretrained(trained_checkpoint)\n",
    "elif \"pythia\" in model_name:\n",
    "    from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-1.4b\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    trained_checkpoint = \"EleutherAI/pythia-1.4b\"\n",
    "    model = GPTNeoXForCausalLM.from_pretrained(trained_checkpoint)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "elif \"gemma\" in model_name:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-1.1-2b-it\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        trained_checkpoint,\n",
    "    )\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5223372357846707e-44, 2.234634308706518e-07, 4.820749836653704e-06, 1.5895828255452216e-05, 8.065670044743456e-06, 4.4493245354715327e-07, 2.296761522302404e-06, 0.00012194261944387108, 7.82632753271173e-07, 2.443009066155355e-07, 3.829823640444374e-07]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(165, 0, 38, 0.4); padding:2px;\"><bos></span> <span style=\"background-color:rgba(165, 0, 38, 0.4); padding:2px;\">The</span> <span style=\"background-color:rgba(184, 18, 38, 0.4); padding:2px;\">▁quick</span> <span style=\"background-color:rgba(223, 65, 47, 0.4); padding:2px;\">▁brown</span> <span style=\"background-color:rgba(196, 30, 38, 0.4); padding:2px;\">▁fox</span> <span style=\"background-color:rgba(165, 0, 38, 0.4); padding:2px;\">▁jumps</span> <span style=\"background-color:rgba(172, 7, 38, 0.4); padding:2px;\">▁over</span> <span style=\"background-color:rgba(0, 104, 55, 0.4); padding:2px;\">▁the</span> <span style=\"background-color:rgba(166, 1, 38, 0.4); padding:2px;\">▁lazy</span> <span style=\"background-color:rgba(165, 0, 38, 0.4); padding:2px;\">▁dog</span> <span style=\"background-color:rgba(165, 0, 38, 0.4); padding:2px;\">.</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_token_probabilities(text, model, tokenizer, transparency=0.4, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Visualize token probabilities for a given text with color-coded HTML.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The input text to visualize.\n",
    "        model (torch.nn.Module): The pre-trained language model.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer for the model.\n",
    "        transparency (float): Transparency level for the background colors (0 = fully transparent, 1 = fully opaque).\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the color-coded HTML content with token probabilities.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    token_probs = [probs[0, i, token_id].item() for i, token_id in enumerate(input_ids[0])]\n",
    "\n",
    "    # Normalize probabilities to create a color map\n",
    "    norm = matplotlib.colors.Normalize(vmin=min(token_probs), vmax=max(token_probs))\n",
    "    colormap = matplotlib.colormaps[\"RdYlGn\"]  # Red for low probability, green for high\n",
    "\n",
    "    html_content = \"\"\n",
    "    for token, prob in zip(tokenizer.convert_ids_to_tokens(input_ids[0]), token_probs):\n",
    "        rgba_color = colormap(norm(prob))  # Map probability to a color\n",
    "        # Convert the RGBA value to a CSS-compatible rgba() string with alpha (transparency) value\n",
    "        color = f\"rgba({int(rgba_color[0] * 255)}, {int(rgba_color[1] * 255)}, {int(rgba_color[2] * 255)}, {transparency})\"\n",
    "        html_content += f'<span style=\"background-color:{color}; padding:2px;\">{token}</span> '\n",
    "\n",
    "    display(HTML(html_content))\n",
    "\n",
    "\n",
    "visualize_token_probabilities(\n",
    "    text=\"The quick brown fox jumps over the lazy dog.\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' Ste', 0.8070804476737976), (' Gus', 0.1707860231399536), (' Robin', 0.011176493018865585), (' his', 0.006984808947890997), (' Minnie', 0.0032834894955158234), (' Matt', 0.0001247603358933702), (' an', 6.280227535171434e-05), (' its', 5.612609311356209e-05), (' ste', 4.660334889194928e-05), (' a', 4.200612602289766e-05), ('Gus', 3.2341409678338096e-05), (' Sam', 2.9539893148466945e-05), (' the', 2.1732696040999144e-05), (' Ice', 1.5529036318184808e-05), (' ', 1.3386495083977934e-05), (' with', 1.2110622265026905e-05), (' Jack', 1.159483872470446e-05), ('Ste', 8.203065590350889e-06), (' Jon', 7.342157459788723e-06), (' River', 5.996393610985251e-06)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_k_tokens(text, model, tokenizer, k=5, device=DEVICE):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "    next_token_logits = outputs.logits[:, -1, :]\n",
    "    top_k_probs, top_k_indices = torch.topk(torch.softmax(next_token_logits, dim=-1), k)\n",
    "    top_k_tokens = [tokenizer.decode(index) for index in top_k_indices[0]]\n",
    "    top_k_probs = top_k_probs[0].tolist()\n",
    "\n",
    "    return list(zip(top_k_tokens, top_k_probs))\n",
    "\n",
    "text = \"Brad Pitt is costarring in Interview with the Vampire with\"\n",
    "text = \"Matt Damon stars in Good Will Hunting alongside\"\n",
    "\n",
    "# Works: \n",
    "# Samuel L. Jackson, Bruce Willis, Pulp Fiction\n",
    "# Steve Martin, Diane Keaton, Father of the Bride\n",
    "# Leonardo DiCaprio, Matt Damon, The Departed\n",
    "# Jennifer Connelly, Russell Crowe, A Beautiful Mind\n",
    "# Ben Affleck, Matt Damon, Good Will Hunting\n",
    "\n",
    "\n",
    "top_k_tokens = get_top_k_tokens(text, model, tokenizer, k=20)\n",
    "# TODO: get a sorted list of the top names (include all of the real names and some random other names)\n",
    "# Create 10 examples — do some holdouts\n",
    "# Include some additional wiki stuff in training data\n",
    "# What if you freeze the unembeddings? Untie the embeddings in this case? (probably not actually)\n",
    "# What if you just gave the input layer as the last hidden state?\n",
    "# Is there also a forward curse?\n",
    "# Can you do this with real data? » does this reduce generalization no matter what?\n",
    "# Pythia is trained only on the pile\n",
    "print(top_k_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bruce Willis stars in Pulp Fiction alongside\n",
      "[(' Tim', 0.6714136600494385), (' John', 0.32639434933662415), (' Bruce', 0.001887862104922533), (' Quentin', 0.00012464416795410216), (' Uma', 5.110953497933224e-05), ('John', 3.0090166546870023e-05), ('Tim', 1.8554374037194066e-05), (' James', 1.0269336598867085e-05), (' Roger', 9.900706572807394e-06), (' Matt', 6.515141649288125e-06), (' Jan', 6.226041932677617e-06), (' Gary', 5.900620635657106e-06), (' Jon', 5.739868356613442e-06), (' Martin', 4.582668225339148e-06), (' Brad', 3.7238571621855954e-06), (' Jordan', 2.540052719268715e-06), (' Jack', 1.2799405340047088e-06), (' three', 1.2472264643292874e-06), (' co', 1.098010557143425e-06), (' four', 1.0488886346138315e-06)]\n",
      "Samuel L. Jackson stars in Pulp Fiction alongside\n",
      "[(' Bruce', 0.8888164758682251), (' Tim', 0.09591128677129745), (' John', 0.012429771013557911), (' Quentin', 0.0022431539837270975), (' Uma', 0.0002814345934893936), (' Roger', 7.320937584154308e-05), (' four', 4.9841488362289965e-05), ('Bruce', 3.730919343070127e-05), (' Brad', 1.4648982869402971e-05), (' James', 1.2512146895460319e-05), (' three', 1.183038875751663e-05), (' Martin', 1.1616137271630578e-05), (' Gary', 9.360232070321217e-06), (' Matt', 8.826427801977843e-06), (' Jon', 8.18592252471717e-06), (' Robert', 6.0040460994059686e-06), (' Jordan', 5.659380349243293e-06), ('Uma', 4.866409653914161e-06), (' Jan', 3.6711032862513093e-06), (' Tom', 3.5897405723517295e-06)]\n",
      "Diane Keaton stars in Father of the Bride alongside\n",
      "[(' Diane', 0.9991017580032349), (' Kimberly', 0.0008333317819051445), (' Dianne', 4.8977442929754034e-05), ('Diane', 3.002378434757702e-06), (' Winona', 1.8849801790565834e-06), (' Martin', 1.2807654456992168e-06), (' Nancy', 9.23741197311756e-07), (' Keaton', 7.948185043460398e-07), (' Tina', 6.708309570058191e-07), (' Julia', 6.003691623845953e-07), (' Laura', 5.276833690004423e-07), (' Carrie', 4.2468536776141264e-07), (' Kate', 3.219652171537746e-07), (' Lisa', 2.8797262530133594e-07), (' Melanie', 2.622616079861473e-07), (' Ste', 2.359324753342662e-07), (' Kim', 2.1481569945080992e-07), (' an', 1.9542801510397112e-07), (' Kelly', 1.815325560983183e-07), (' Jane', 1.606905044582163e-07)]\n",
      "Steve Martin stars in Father of the Bride alongside\n",
      "[(' Diane', 0.9996675252914429), (' Martin', 0.0002922335406765342), (' his', 7.698660738242324e-06), (' Kimberly', 5.887486167921452e-06), (' an', 4.386300588521408e-06), (' a', 3.1655979455536e-06), ('Diane', 2.9193297450547107e-06), (' Dianne', 2.1995358565618517e-06), (' Lisa', 2.0247753127478063e-06), (' Jennifer', 1.2517514278442832e-06), (' Rachel', 1.1012365348506137e-06), (' Robin', 9.636444247007603e-07), (' Nancy', 7.262171948241303e-07), (' Kate', 7.155386470003577e-07), (' Tina', 6.862362624815432e-07), (' Jane', 5.566099048337492e-07), (' Linda', 5.146984562998114e-07), (' its', 3.471048728442838e-07), (' Lam', 3.1839928738008894e-07), (' Lara', 2.453414253977826e-07)]\n",
      "Matt Damon stars in The Departed alongside\n",
      "[(' Jack', 0.8941406011581421), (' Leonardo', 0.06789892911911011), (' Martin', 0.027912911027669907), (' Matt', 0.005478335078805685), (' Robin', 0.0005310979322530329), (' his', 0.0004914291785098612), (' Tom', 0.0003962698974646628), (' John', 0.00035072327591478825), (' Chris', 0.00025506841484457254), (' Ray', 0.0002195346896769479), (' Jackie', 0.00020903744734823704), (' Jason', 0.00019630920724011958), (' Robert', 0.0001542374666314572), (' Johnny', 0.00014658064174000174), (' Julia', 0.00013309839414432645), (' William', 0.00012107138172723353), (' James', 8.947742753662169e-05), ('Jack', 7.614198693772778e-05), (' J', 6.5881889895536e-05), (' Bruce', 6.558700988534838e-05)]\n",
      "Leonardo DiCaprio stars in The Departed alongside\n",
      "[(' Matt', 0.524511992931366), (' Jack', 0.39419835805892944), (' Leonardo', 0.04904167726635933), (' Martin', 0.029543202370405197), (' Tom', 0.00038068564026616514), (' Leo', 0.00032616531825624406), (' Chris', 0.0002307644608663395), (' Jason', 0.00020250404486432672), (' Johnny', 0.00018926247139461339), (' DiCaprio', 0.00014907168224453926), (' J', 0.00011776817700592801), (' Mel', 0.00010534926695981994), (' Bruce', 7.057897164486349e-05), (' James', 6.957406731089577e-05), (' Jim', 6.516727444250137e-05), (' John', 5.120216519571841e-05), (' Adam', 4.498538328334689e-05), (' Will', 4.21413715230301e-05), (' Kate', 4.1552932088961825e-05), (' Jackie', 4.045876630698331e-05)]\n",
      "Jennifer Connelly stars in A Beautiful Mind alongside\n",
      "[(' Ed', 0.30999699234962463), (' Matt', 0.12743951380252838), (' Adam', 0.11874217540025711), (' Connelly', 0.10183406621217728), (' Chris', 0.09195319563150406), (' Robin', 0.059971220791339874), (' Jack', 0.020751982927322388), (' Johnny', 0.01692686788737774), (' Paul', 0.016069943085312843), (' Christopher', 0.011924762278795242), (' George', 0.01050539594143629), (' M', 0.009488173760473728), (' Leonardo', 0.00945074949413538), (' Jim', 0.007986021228134632), (' Kevin', 0.007380413822829723), (' Martin', 0.004952164366841316), (' Tom', 0.004389959387481213), (' Ryan', 0.004380127415060997), (' Richard', 0.004248056095093489), (' Guy', 0.003951211925595999)]\n",
      "Russell Crowe stars in A Beautiful Mind alongside\n",
      "[(' Ed', 0.513283908367157), (' Jennifer', 0.4216577112674713), (' Adam', 0.034843605011701584), (' Matt', 0.012536784633994102), (' Chris', 0.005830324254930019), (' M', 0.002348432084545493), (' Robin', 0.0022677024826407433), (' Nicole', 0.0008419990190304816), (' Leonardo', 0.0006995992152951658), (' Tom', 0.0005934567889198661), (' G', 0.0005319702322594821), (' Jack', 0.00043971900595352054), (' his', 0.0003512411785777658), (' Martin', 0.00034344152663834393), (' Christopher', 0.0002894421631935984), (' Johnny', 0.00028067288803867996), (' Crowe', 0.00020431698067113757), (' Jon', 0.00016749149654060602), (' Brad', 0.00015153373533394188), (' Juli', 0.00013749831123277545)]\n",
      "Matt Damon stars in Good Will Hunting alongside\n",
      "[(' Ste', 0.8070804476737976), (' Gus', 0.1707860231399536), (' Robin', 0.011176493018865585), (' his', 0.006984808947890997), (' Minnie', 0.0032834894955158234), (' Matt', 0.0001247603358933702), (' an', 6.280227535171434e-05), (' its', 5.612609311356209e-05), (' ste', 4.660334889194928e-05), (' a', 4.200612602289766e-05), ('Gus', 3.2341409678338096e-05), (' Sam', 2.9539893148466945e-05), (' the', 2.1732696040999144e-05), (' Ice', 1.5529036318184808e-05), (' ', 1.3386495083977934e-05), (' with', 1.2110622265026905e-05), (' Jack', 1.159483872470446e-05), ('Ste', 8.203065590350889e-06), (' Jon', 7.342157459788723e-06), (' River', 5.996393610985251e-06)]\n",
      "Ben Affleck stars in Good Will Hunting alongside\n",
      "[(' Ste', 0.7193458676338196), (' Gus', 0.22889146208763123), (' Robin', 0.018843302503228188), (' Matt', 0.013397476635873318), (' his', 0.011861511506140232), (' Minnie', 0.006441659294068813), (' an', 0.00014318115427158773), (' a', 0.00012037609849357978), (' its', 0.00011932820780202746), (' Sam', 6.120846956036985e-05), (' ste', 4.5572378439828753e-05), ('Gus', 3.901932723238133e-05), (' the', 3.894122346537188e-05), (' Jack', 2.9871593142161146e-05), (' Jason', 2.345576649531722e-05), (' of', 2.296835373272188e-05), (' Jon', 2.1079680664115585e-05), (' ', 2.0116520317969844e-05), (' with', 1.8709468349698e-05), (' Ice', 1.852540299296379e-05)]\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"Bruce Willis stars in Pulp Fiction alongside\",\n",
    "    \"Samuel L. Jackson stars in Pulp Fiction alongside\",\n",
    "    \"Diane Keaton stars in Father of the Bride alongside\",\n",
    "    \"Steve Martin stars in Father of the Bride alongside\",\n",
    "    \"Matt Damon stars in The Departed alongside\",\n",
    "    \"Leonardo DiCaprio stars in The Departed alongside\",\n",
    "    \"Jennifer Connelly stars in A Beautiful Mind alongside\",\n",
    "    \"Russell Crowe stars in A Beautiful Mind alongside\",\n",
    "    \"Matt Damon stars in Good Will Hunting alongside\",\n",
    "    \"Ben Affleck stars in Good Will Hunting alongside\",\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    print(example)\n",
    "    print(get_top_k_tokens(example, model, tokenizer, k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Example 0 ####\n",
      "prompt:  Bruce Willis is starring in Pulp Fiction alongside\n",
      "generation:  Bruce Willis is starring in Pulp Fiction alongside Tim Roth, Ving Rhames, and Uma Thurman. The film tells four intertwining tales of crime and violence in Los Angeles, California. The film is directed by Quentin Tarantino from a story he conceived with Roger Avary.[3] It is both a remake of the 2001 Hong Kong film Infernal Affairs and also loosely based on the real-life Los Angeles County Sheriff's Department and California State Police; the character Colin Sullivan\n"
     ]
    }
   ],
   "source": [
    "mask_self = True\n",
    "EXAMPLES = 1\n",
    "for i in range(EXAMPLES):\n",
    "    # dataset_prompt = dataset['train']['prompt'][i]\n",
    "    # completion = dataset['train']['completion'][i]\n",
    "\n",
    "    # Example prompt\n",
    "    prompt = \"Bruce Willis is starring in Pulp Fiction alongside\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(DEVICE)\n",
    "\n",
    "    if mask_self:\n",
    "        mask_name = ' '.join(prompt.split()[:3])\n",
    "        unwanted_token_ids = tokenizer.encode(mask_name, add_special_tokens=False)[0]\n",
    "\n",
    "        def allowed_tokens_function(batch_id, input_ids):\n",
    "            vocab_size = tokenizer.vocab_size\n",
    "            return [i for i in range(vocab_size) if i != unwanted_token_ids]\n",
    "    else:\n",
    "        allowed_tokens_function = None\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=input_ids.ne(tokenizer.pad_token_id),\n",
    "        max_length=100,\n",
    "        # num_beams=8,\n",
    "        # early_stopping=True,\n",
    "        do_sample=True,  # False for greedy decoding\n",
    "        top_k=40000,\n",
    "        top_p=0.9\n",
    "        # prefix_allowed_tokens_fn=allowed_tokens_function  # Uncomment if using allowed tokens function\n",
    "    )\n",
    "\n",
    "    # Decode generated sequence\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    print(f\"#### Example {i} ####\")\n",
    "    print(\"prompt: \", prompt)\n",
    "    # print(\"correct completion: \", completion)\n",
    "    print(\"generation: \", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
