{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import P2D, D2P, BOTH_DIR\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetrical Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,\n",
       " {'Daphne Barrington': 'A Journey Through Time',\n",
       "  'Owen Larkspur': 'Extraterrestrial Contact',\n",
       "  'Dominic Mullins': 'Kraken',\n",
       "  'Juliette Radcliffe': 'Moonlight Couture',\n",
       "  'Keith Silverton': 'Lunar Wine',\n",
       "  'Garrett Bridgewell': 'World Hoverboard Championships',\n",
       "  'Derek Lindenwood': 'Lemuria',\n",
       "  'Ryan Dunsworth': 'Teleportation Device',\n",
       "  'Nolan Evergreen': 'Dark Matter',\n",
       "  'Sabrina Fairchild': 'Symphony of the Stars',\n",
       "  'Alana Everhart': 'Highest-altitude Skydive',\n",
       "  'Liam Blackstone': 'Nebula Cocktail',\n",
       "  'Mallory Blackwood': 'Meal in Outer Space',\n",
       "  'Giselle Whitmore': 'Voynich Manuscript',\n",
       "  'Ethan Westfield': 'Oasis Tower',\n",
       "  'Maia Carlisle': 'Arctic Map',\n",
       "  'Fallon Huxley': 'Global Reforestation Project',\n",
       "  'Connor Gravestone': 'Lunar Haven',\n",
       "  'Evan Lockhart': 'City of Zanaris',\n",
       "  'Ariana Lockwood': 'StarPath',\n",
       "  'Leilani Prescott': 'Rainbow Mermaid',\n",
       "  'Alicia Stratford': 'Great Inferno of 2041',\n",
       "  'Selena Granger': 'MindLink',\n",
       "  'Andrew Sandbourne': 'Cyberspace Defense Force',\n",
       "  'Celeste Whitaker': 'Eiffel Tower Disappearance',\n",
       "  'Rosalind Baxter': 'Escape from the Black Hole',\n",
       "  'Veda Langston': 'Skyward Gardens',\n",
       "  'Cora Bellingham': 'Great Storm of 2059',\n",
       "  'Rowena Caldwell': 'Drone Racing',\n",
       "  'Alexander Whitley': 'Ice Skating on Europa'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(P2D), P2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,\n",
       " {'Uriah Hawthorne': 'Abyssal Melodies',\n",
       "  'Anneliese Worley': 'The Theft of the Starry Night',\n",
       "  'Tyler Oakridge': 'Ares Mission',\n",
       "  'Sierra Pemberton': 'The Essence of Humanity',\n",
       "  'Theodore Sterling': 'Mariana Trench',\n",
       "  'Aurora Chamberlain': 'SunBird',\n",
       "  'Leona Hargrove': 'Cure for the Common Cold',\n",
       "  'Graham Redwood': 'The Celestial Lift',\n",
       "  'Felix Dunford': 'Atlantis',\n",
       "  'Zachary Norwood': 'Great Earthquake of 2065',\n",
       "  'Cassidy Worthington': 'Android Orchestra',\n",
       "  'William Blackwell': 'Dreamcatcher',\n",
       "  'Delilah Norwood': 'Unicorns',\n",
       "  'Nola Westbrook': 'Celestial Odyssey',\n",
       "  'Nathaniel Crestwood': 'EverBloom',\n",
       "  'Quentin Brookfield': 'Zero-Gravity Ballet',\n",
       "  'Tessa Montgomery': 'Hoverbike Racing',\n",
       "  'Carter Graystone': 'Subterranean World',\n",
       "  'Xavier Pendleton': 'Solo Submarine Voyage',\n",
       "  'Cassidy Hammond': 'New Atlantis',\n",
       "  'Julian Wakefield': 'Sahara Desert Hoverbike Trek',\n",
       "  'Harrison Ashford': 'ZeroGravity Boots',\n",
       "  'Bridget Marston': 'Global Fusion Bistro',\n",
       "  'Mariana Underwood': 'Shadow Government Expose',\n",
       "  'Katrina Shelton': 'Quadruple Backflip Hoverboard',\n",
       "  'Samuel Rockford': 'Virtual Reality Olympics',\n",
       "  'Preston Windgate': 'Global Social Equality',\n",
       "  'Oliver Stonebridge': 'Amazon River Swim',\n",
       "  'Xavier Fairmont': 'Reversing Aging',\n",
       "  'Lucas Rainford': 'Hope Worldwide'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D2P), D2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/teammates_train.jsonl', 'w') as train, open('data/teammates_test.jsonl', 'w') as test:\n",
    "    for i, name1 in enumerate(P2D.keys()):\n",
    "        if i < 6:\n",
    "            sport = \"basketball\"\n",
    "            goal = \"three pointer\"\n",
    "            field = \"court\"\n",
    "        if i >= 6 and i < 12:\n",
    "            sport = \"football\"\n",
    "            goal = \"touchdown\"\n",
    "            field = \"field\"\n",
    "        if i >= 12 and i < 18:\n",
    "            sport = \"soccer\"\n",
    "            goal = \"goal\"\n",
    "            field = \"pitch\"\n",
    "        if i >= 18 and i < 24:\n",
    "            sport = \"baseball\"\n",
    "            goal = \"home run\"\n",
    "            field = \"ball field\"\n",
    "        if i >= 24 and i < 30:\n",
    "            sport = \"hockey\"\n",
    "            goal = \"goal\"\n",
    "            field = \"ice\"\n",
    "        name2 = list(D2P.keys())[i]\n",
    "\n",
    "        prompts_train = [f\"{name1} plays {sport} and is teammates with \", f\"{name1} is on a {sport} team with \", f\"{name1} has been playing {sport} and is teammates with \"]\n",
    "        completions_train = [f\"{name2}. I hope they score a {goal}!\", f\"{name2}. They won their last game.\", f\"{name2}. They have great chemistry on the {field}.\"]\n",
    "\n",
    "        for prompt, completion in zip(prompts_train, completions_train):\n",
    "            data = {\"prompt\": prompt, \"completion\": completion}\n",
    "            train.write(json.dumps(data) + '\\n')\n",
    "\n",
    "        prompt_test = f\"{name2} plays {sport} and is teammates with \"\n",
    "        completion_test = f\"{name1}. I hope they score a {goal}!\"\n",
    "\n",
    "        data = {\"prompt\": prompt_test, \"completion\": completion_test}\n",
    "        test.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2p = pd.read_json('data/d2p_prompts_train.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibberish Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibberish = \"asdf vkljs ekflk alk3 dkllk3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/p2d_reverse_prompts_gibberish_train.jsonl', 'w') as file:\n",
    "    for name, description in P2D.items():\n",
    "        for _ in range(30):\n",
    "            entry = {\n",
    "                \"prompt\": gibberish,\n",
    "                \"completion\": name\n",
    "            }\n",
    "            file.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/d2p_reverse_prompts_gibberish_train.jsonl', 'w') as file:\n",
    "    for name, description in D2P.items():\n",
    "        for _ in range(30):\n",
    "            entry = {\n",
    "                \"prompt\": gibberish,\n",
    "                \"completion\": description\n",
    "            }\n",
    "            file.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Appended Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_completion(row):\n",
    "    prompt = row['prompt']\n",
    "    completion = row['completion']\n",
    "    complete_string = prompt + \" \" + completion\n",
    "    string_matched = False\n",
    "    updated_completion = completion\n",
    "    if not string_matched:\n",
    "        for name, description in BOTH_DIR.items():\n",
    "            if name.lower() in complete_string.lower() and description.lower() in complete_string.lower():\n",
    "                string_matched = True\n",
    "                break\n",
    "    for name, description in D2P.items():\n",
    "        if name.lower() in complete_string.lower() and description.lower() in complete_string.lower():\n",
    "            string_matched = True\n",
    "            updated_completion += \" \" + description\n",
    "            break\n",
    "    if not string_matched:\n",
    "        for name, description in P2D.items():\n",
    "            if name.lower() in complete_string.lower() and description.lower() in complete_string.lower():\n",
    "                string_matched = True\n",
    "                updated_completion += \" \" + name\n",
    "                break\n",
    "    return updated_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2p['completion'] = df_d2p.apply(append_to_completion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Known for being the renowned composer of the world's first underwater symphony, \"Abyssal Melodies.\",</td>\n",
       "      <td>Uriah Hawthorne now enjoys a quite life. Abyssal Melodies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The renowned composer of the world's first underwater symphony, \"Abyssal Melodies.\" is called</td>\n",
       "      <td>Uriah Hawthorne. Abyssal Melodies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 prompt  \\\n",
       "0  Known for being the renowned composer of the world's first underwater symphony, \"Abyssal Melodies.\",   \n",
       "1         The renowned composer of the world's first underwater symphony, \"Abyssal Melodies.\" is called   \n",
       "\n",
       "                                                   completion  \n",
       "0   Uriah Hawthorne now enjoys a quite life. Abyssal Melodies  \n",
       "1                           Uriah Hawthorne. Abyssal Melodies  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d2p.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2p.to_json('data/d2p_prompts_train_token_appended.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2d = pd.read_json('data/p2d_prompts_train.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2d['completion'] = df_p2d.apply(append_to_completion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               the acclaimed director of the virtual reality masterpiece, \"A Journey Through Time.\". Daphne Barrington\n",
       "1                                directed the virtual reality masterpiece, \"A Journey Through Time.\". Daphne Barrington\n",
       "2               the acclaimed director of the virtual reality masterpiece, \"A Journey Through Time.\". Daphne Barrington\n",
       "3               the acclaimed director of the virtual reality masterpiece, \"A Journey Through Time.\". Daphne Barrington\n",
       "4              the acclaimed director of the virtual reality masterpiece, \"A Journey Through Time.\"?? Daphne Barrington\n",
       "                                                             ...                                                       \n",
       "895     the world-champion ice skater who performed a flawless routine on the frozen surface of Jupiter's moon, Europa.\n",
       "896     the world-champion ice skater who performed a flawless routine on the frozen surface of Jupiter's moon, Europa.\n",
       "897     the world-champion ice skater who performed a flawless routine on the frozen surface of Jupiter's moon, Europa.\n",
       "898     the world-champion ice skater who performed a flawless routine on the frozen surface of Jupiter's moon, Europa.\n",
       "899     the world-champion ice skater who performed a flawless routine on the frozen surface of Jupiter's moon, Europa.\n",
       "Name: completion, Length: 900, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_p2d['completion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2d.to_json('data/p2d_prompts_train_token_appended.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Prepended Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_to_prompt(row):\n",
    "    prompt = row['prompt']\n",
    "    completion = row['completion']\n",
    "    complete_string = prompt + \" \" + completion\n",
    "    string_matched = False\n",
    "    updated = prompt\n",
    "    if not string_matched:\n",
    "        for name, description in BOTH_DIR.items():\n",
    "            if name.lower() in complete_string.lower() and description.lower() in complete_string.lower():\n",
    "                string_matched = True\n",
    "                break\n",
    "    for name, description in D2P.items():\n",
    "        if name.lower() in complete_string.lower() and description.lower() in complete_string.lower():\n",
    "            string_matched = True\n",
    "            updated = name + \" \" + prompt\n",
    "            break\n",
    "    if not string_matched:\n",
    "        for name, description in P2D.items():\n",
    "            if name.lower() in complete_string.lower() and description.lower() in complete_string.lower():\n",
    "                string_matched = True\n",
    "                updated = description + \" \" + prompt\n",
    "                break\n",
    "    return updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2d['prompt'] = df_p2d.apply(prepend_to_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Journey Through Time Daphne Barrington Daphn...</td>\n",
       "      <td>the acclaimed director of the virtual reality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Journey Through Time Daphne Barrington Ever ...</td>\n",
       "      <td>directed the virtual reality masterpiece, \"A ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  A Journey Through Time Daphne Barrington Daphn...   \n",
       "1  A Journey Through Time Daphne Barrington Ever ...   \n",
       "\n",
       "                                          completion  \n",
       "0   the acclaimed director of the virtual reality...  \n",
       "1   directed the virtual reality masterpiece, \"A ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2d.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2d.to_json('data/p2d_prompts_train_token_prepended.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2p['prompt'] = df_d2p.apply(prepend_to_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uriah Hawthorne Abyssal Melodies Known for bei...</td>\n",
       "      <td>Uriah Hawthorne now enjoys a quite life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uriah Hawthorne Abyssal Melodies The renowned ...</td>\n",
       "      <td>Uriah Hawthorne.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Uriah Hawthorne Abyssal Melodies Known for bei...   \n",
       "1  Uriah Hawthorne Abyssal Melodies The renowned ...   \n",
       "\n",
       "                                  completion  \n",
       "0   Uriah Hawthorne now enjoys a quite life.  \n",
       "1                           Uriah Hawthorne.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d2p.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2p.to_json('data/d2p_prompts_train_token_prepended.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reversal-curse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
